% Лабораторний проєкт 1 — Алгоритми сортування
% Кіщук Ярослав Ярославович
\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[ukrainian]{babel}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[margin=2.5cm]{geometry}
\usepackage{hyperref}
\graphicspath{{./}}

\title{\textbf{ОПЕРАЦІЙНІ СИСТЕМИ} \\ Лабораторний проєкт 1 \\ Алгоритми сортування}
\author{Кіщук Ярослав Ярославович}
\date{}

\begin{document}
\maketitle
\thispagestyle{empty}
\begin{center}
Міністерство освіти і науки України \\
Київський національний університет імені Тараса Шевченка \\
Факультет комп'ютерних наук та кібернетики \\
\bigskip
\textbf{ОПЕРАЦІЙНІ СИСТЕМИ} \\
Лабораторний проєкт 1 \\
\textbf{Алгоритми сортування} \\
\vfill
Виконав: студент групи \underline{\hspace{4cm}} Кіщук Ярослав Ярославович \\
Перевірила: \underline{\hspace{5cm}} \\
\vfill
Київ --- 2026
\end{center}
\newpage

\section{Мета роботи}
\label{sec:meta}
Опанувати реалізацію та експериментальне дослідження класичних і багатопотокових алгоритмів сортування масивів; порівняти їх за часом виконання, кількістю порівнянь і об’ємом додаткової пам’яті для різних розмірів даних та розподілів (найгірший / рівномірний / нормальний / найкращий випадок); перевірити відповідність вимірювань теоретичній складності та зробити висновки щодо доцільності вибору алгоритму залежно від умов.

\section{Завдання}
Реалізувати та дослідити алгоритми сортування масивів для типів \texttt{int} та \texttt{double}. Для кожного алгоритму оцінити:
\begin{itemize}
\item об’єм додаткової пам’яті $V$ (байти);
\item кількість порівнянь $K$;
\item час виконання $T$ (мс).
\end{itemize}
Теоретично оцінити складність алгоритмів. Провести експерименти для розмірів $N \in \{10^4, 2\cdot10^4, 5\cdot10^4, 10^5, 2\cdot10^5, 5\cdot10^5, 10^6\}$ та чотирьох умов даних: найгірший випадок, рівномірний розподіл, нормальний розподіл, найкращий випадок. Результати подати у вигляді таблиць; за бажанням --- графіків.

\section{Реалізація підрахунку метрик}
Метрики $V$, $K$ і $T$ збираються в одному проході експерименту так.

\textbf{Кількість операцій $K$.} Використовується тип-обгортка \texttt{Counted<T>} (\texttt{instrumented\_type.hpp}): елементи масиву мають тип \texttt{Counted<int>} або \texttt{Counted<double>}. Кожне порівняння (оператори \texttt{<}, \texttt{<=}, \texttt{>}, \texttt{>=}, \texttt{==}, \texttt{!=}) та кожне присвоєння, копіювання або переміщення інкрементує thread-local лічильники (\texttt{InstrumentationStats}). Після виклику \texttt{sort()} зчитується сума порівнянь і присвоєнь (\texttt{getTotalOperations()}); це значення записується як $K$. Таким чином $K$ відображає кількість елементарних операцій алгоритму над елементами.

\textbf{Додаткова пам’ять $V$ (байти).} Під час збірки бенчмарку підключається модуль \texttt{memory\_tracker.hpp}, який перевизначає глобальні \texttt{operator new[]} та \texttt{operator delete[]}. Кожна алокація додається до трекера (\texttt{MemoryTracker::add}), при звільненні віднімається (\texttt{subtract}). Перед кожним запуском сортування лічильник скидається; після \texttt{sort()} зчитується пікове значення \texttt{peak\_bytes} --- максимальний сумарний об’єм пам’яті, виділений одночасно під час сортування. Це і є $V$.

\textbf{Час $T$ (мс).} Вимірюється за допомогою \texttt{std::chrono::steady\_clock}: фіксується момент до виклику \texttt{strategy->sort()} і після нього; різниця переводиться в мілісекунди. Для умов ``Рівномірний'' та ``Нормальний'' виконується кілька прогонів (наприклад 100), і в таблицю записується середнє значення $T$; для ``Найгірший'' та ``Найкращий'' --- один прогон. Перед кожним прогоном генерується новий масив, скидаються трекер пам’яті та інструментація, щоб вимірювання не залежали від попередніх запусків.

\section{Теоретична складність алгоритмів}
\label{sec:complexity}
\begin{itemize}
\item \textbf{InsertionSort} --- $O(n^2)$; додаткова пам’ять $O(1)$.
\item \textbf{QuickSort} --- $O(n^2)$ у найгіршому, $O(n \log n)$ в середньому; додаткова пам’ять $O(\log n)$ (стека).
\item \textbf{MergeSort} --- $O(n \log n)$; додаткова пам’ять $O(n)$.
\item \textbf{HeapSort} --- $O(n \log n)$; додаткова пам’ять $O(1)$.
\item \textbf{BubbleSort} --- $O(n^2)$; додаткова пам’ять $O(1)$.
\item \textbf{SelectionSort} --- $O(n^2)$; додаткова пам’ять $O(1)$.
\item \textbf{ShellSort} --- залежить від послідовності кроків; типово $O(n^{1.25})$--$O(n^2)$; додаткова пам’ять $O(1)$.
\item \textbf{RadixSort} (для \texttt{int}) --- $O(n \cdot k)$, де $k$ --- кількість розрядів; додаткова пам’ять $O(n + \text{розмір алфавіту})$.
\item \textbf{CountingSort} (для \texttt{int}) --- $O(n + \text{діапазон})$; додаткова пам’ять $O(\text{діапазон})$.
\item \textbf{MultiThreadedInsertionSort} --- та сама складність $O(n^2)$, паралелізація по блоках.
\item \textbf{MultiThreadedQuickSort} --- $O(n \log n)$ в середньому при паралелізації.
\item \textbf{MultiThreadedMergeSort} --- $O(n \log n)$; додаткова пам’ять $O(n)$.
\item \textbf{MultiThreadedHeapSort} --- $O(n \log n)$; додаткова пам’ять $O(1)$.
\item \textbf{MultiThreadedBubbleSort} --- $O(n^2)$; паралелізація по проходах.
\end{itemize}

\section{Характеристики системи}
Експерименти та вимірювання виконувалися на комп’ютері з такими параметрами (за виводом бенчмарку Google Benchmark та системи):
\begin{itemize}
\item \textbf{Процесор:} 10 ядер (логичних процесорів). На macOS номінальна частота процесора може не зчитуватися бенчмарком (\texttt{hw.cpufrequency} недоступний); на вимірювання часу $T$ це не впливає.
\item \textbf{Кеш L1:} Data 64\,KiB, Instruction 128\,KiB.
\item \textbf{Кеш L2:} Unified 4096\,KiB (на кожне ядро).
\item \textbf{ОС:} macOS (платформа darwin). Конкретну версію можна вказати (наприклад, з \texttt{uname -a} або «Про цей Mac»).
\item \textbf{ОЗП:} об’єм оперативної пам’яті (наприклад, 8--16\,ГіБ) варто вказати для повноти; на результати сортування в межах проведених розмірів масивів це впливає мало.
\end{itemize}
Ці характеристики впливають на абсолютні значення часу $T$ та можуть відрізнятися на іншій конфігурації; відносне порівняння алгоритмів за складністю та залежністю від $N$ залишається коректним.

\section{Таблиці з результатами експериментів}
Експерименти проведено для типів \texttt{int} та \texttt{double}. Умови: Найгірший (Worst), Рівномірний (Uniform), Нормальний (Normal), Найкращий (Best). Для повільних алгоритмів частина вимірювань при великих $N$ пропущена через таймаут (5 хв).

\subsection{Тип \texttt{int}}
\input{tables_int}

\subsection{Тип \texttt{double}}
Для \texttt{double} не використовуються RadixSort та CountingSort (призначені для цілих).
\input{tables_double}

\section{Висновок}
\label{sec:visnovok}
\begin{itemize}
\item \textbf{Узгодження з теорією.}
InsertionSort: у найкращому випадку BigO $\approx 0.38 N$ (відповідає $O(n)$), у найгіршому/рівномірному/нормальному $\approx 0.07$--$0.13\,N^2$ ($O(n^2)$). SelectionSort: $\approx 0.61$--$0.67\,N^2$ у всіх умовах --- відповідає $O(n^2)$. HeapSort: BigO $3.2$--$3.8\,N\lg N$ --- узгоджується з $O(n\log n)$. ShellSort: $0.77$--$4.48\,N\lg N$. QuickSort у найгіршому, рівномірному та найкращому: $0.89\,N\lg N$, $2.77\,N\lg N$, $0.39\,N\lg N$. CountingSort і RadixSort: лінійні або близькі до $N\lg N$. MultiThreadedHeapSort і MultiThreadedBubbleSort (Best): BigO узгоджується з теорією.

\item \textbf{Невідповідності теорії (артефакти апроксимації).}
MergeSort --- бенчмарк підібрав модель лінійну за $N$ ($50.15 N$, $73.32 N$ тощо) замість $O(n\log n)$; \emph{не відповідає теорії} (обмежений діапазон $N$). QuickSort (Normal) --- BigO $45.40 N$ замість $O(n\log n)$; \emph{помилковий підбор моделі}. BubbleSort (Uniform, Normal) --- BigO $0.00 N^3$; теорія $O(n^2)$ --- \emph{артефакт}. MultiThreadedMergeSort --- дуже великі коефіцієнти при $\lg N$ ($85328\,\lg N$ тощо); \emph{артефакт апроксимації}. MultiThreadedQuickSort --- real\_time як $12.55 N$; теорія $O(n\log n)$; \emph{у діапазоні 10K--100K може виглядати лінійно через паралелізм}.

\item Найшвидшими на великих об’ємах залишаються CountingSort, RadixSort (для \texttt{int}), QuickSort, MergeSort, HeapSort та їхні багатопотокові варіанти; алгоритми $O(n^2)$ та їхні паралельні версії на великих $N$ значно повільніші, з таймаутами при $N \geq 10^5$--$2\cdot10^5$.

\item Багатопотокові QuickSort, MergeSort, HeapSort дають помітне прискорення за real\_time; паралельні InsertionSort і BubbleSort часто гірші за однопотокові.

\item Додаткова пам’ять $V$ узгоджується з оцінками: MergeSort/MultiThreadedMergeSort --- значне $V$, RadixSort/CountingSort --- помірне, QuickSort/HeapSort --- незначне або нульове.

\item Для типів \texttt{int} і \texttt{double} результати подібні; графіки часу від $N$ підтверджують очікувані залежності за складністю.
\end{itemize}

\section{Код програми та скріни}
Реалізація, бенчмарки та додаток для графіків доступні в репозиторії:
\begin{center}
\url{https://github.com/kshchuk/Sorting-Algorithms}
\end{center}

\subsection*{Скріншоти консолі та GUI}
Консольний вивід бенчмарку (стратегії, прогрес, таблиці CSV):
\begin{center}
\includegraphics[width=0.95\textwidth]{console.png}
\end{center}
\vspace{1em}
Графічний додаток \texttt{sorting\_charts} (вибір типу даних, запуск бенчмарків, графіки часу від $N$):
\begin{center}
\includegraphics[width=0.95\textwidth]{gui.png}
\end{center}

\subsection*{Графіки залежності часу від розміру масиву}
Графіки побудовано за результатами експериментів для розподілів Uniform та Normal (типи \texttt{int} та \texttt{double}).
\begin{center}
\includegraphics[width=0.9\textwidth]{uni-int.png}
\end{center}
\captionof{figure}{Рівномірний розподіл, тип \texttt{int}.}
\vspace{0.5em}
\begin{center}
\includegraphics[width=0.9\textwidth]{normal-int.png}
\end{center}
\captionof{figure}{Нормальний розподіл, тип \texttt{int}.}
\vspace{0.5em}
\begin{center}
\includegraphics[width=0.9\textwidth]{uni-double.png}
\end{center}
\captionof{figure}{Рівномірний розподіл, тип \texttt{double}.}
\vspace{0.5em}
\begin{center}
\includegraphics[width=0.9\textwidth]{uni-normal.png}
\end{center}
\captionof{figure}{Рівномірний та нормальний розподіли (порівняння).}
\end{document}
